import {
  require_src2 as require_src
} from "./chunk-3IA7NUK6.js";
import {
  __commonJS
} from "./chunk-G3PMV62Z.js";

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/util/constants.js
var require_constants = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/util/constants.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.CREDENTIAL_ERROR_MESSAGE = exports.USER_AGENT = exports.SYSTEM_ROLE = exports.MODEL_ROLE = exports.USER_ROLE = exports.COUNT_TOKENS_METHOD = exports.STREAMING_GENERATE_CONTENT_METHOD = exports.GENERATE_CONTENT_METHOD = void 0;
    exports.GENERATE_CONTENT_METHOD = "generateContent";
    exports.STREAMING_GENERATE_CONTENT_METHOD = "streamGenerateContent";
    exports.COUNT_TOKENS_METHOD = "countTokens";
    exports.USER_ROLE = "user";
    exports.MODEL_ROLE = "model";
    exports.SYSTEM_ROLE = "system";
    var USER_AGENT_PRODUCT = "model-builder";
    var CLIENT_LIBRARY_VERSION = "1.9.3";
    var CLIENT_LIBRARY_LANGUAGE = `grpc-node/${CLIENT_LIBRARY_VERSION}`;
    exports.USER_AGENT = `${USER_AGENT_PRODUCT}/${CLIENT_LIBRARY_VERSION} ${CLIENT_LIBRARY_LANGUAGE}`;
    exports.CREDENTIAL_ERROR_MESSAGE = "\nUnable to authenticate your request        \nDepending on your run time environment, you can get authentication by        \n- if in local instance or cloud shell: `!gcloud auth login`        \n- if in Colab:        \n    -`from google.colab import auth`        \n    -`auth.authenticate_user()`        \n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication";
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/util/index.js
var require_util = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/util/index.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.constants = void 0;
    exports.constants = require_constants();
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/util.js
var require_util2 = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/util.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.formulateSystemInstructionIntoContent = void 0;
    var util_1 = require_util();
    function formulateSystemInstructionIntoContent(systemInstruction) {
      if (typeof systemInstruction === "string") {
        return {
          role: util_1.constants.SYSTEM_ROLE,
          parts: [{ text: systemInstruction }]
        };
      }
      systemInstruction.role = util_1.constants.SYSTEM_ROLE;
      return systemInstruction;
    }
    exports.formulateSystemInstructionIntoContent = formulateSystemInstructionIntoContent;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/errors.js
var require_errors = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/errors.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.IllegalArgumentError = exports.GoogleGenerativeAIError = exports.GoogleAuthError = exports.GoogleApiError = exports.ClientError = void 0;
    var GoogleAuthError = class extends Error {
      constructor(message, stackTrace) {
        super(message, { cause: stackTrace });
        this.message = constructErrorMessage("GoogleAuthError", message);
        this.name = "GoogleAuthError";
        this.stackTrace = stackTrace;
      }
    };
    exports.GoogleAuthError = GoogleAuthError;
    var ClientError = class extends Error {
      constructor(message, stackTrace) {
        super(message, { cause: stackTrace });
        this.message = constructErrorMessage("ClientError", message);
        this.name = "ClientError";
        this.stackTrace = stackTrace;
      }
    };
    exports.ClientError = ClientError;
    var GoogleApiError = class extends Error {
      constructor(message, code, status, errorDetails) {
        super(message);
        this.code = code;
        this.status = status;
        this.errorDetails = errorDetails;
      }
    };
    exports.GoogleApiError = GoogleApiError;
    var GoogleGenerativeAIError = class extends Error {
      constructor(message, stackTrace) {
        super(message, { cause: stackTrace });
        this.message = constructErrorMessage("GoogleGenerativeAIError", message);
        this.name = "GoogleGenerativeAIError";
        this.stackTrace = stackTrace;
      }
    };
    exports.GoogleGenerativeAIError = GoogleGenerativeAIError;
    var IllegalArgumentError = class extends Error {
      constructor(message, stackTrace) {
        super(message, { cause: stackTrace });
        this.message = constructErrorMessage("IllegalArgumentError", message);
        this.name = "IllegalArgumentError";
        this.stackTrace = stackTrace;
      }
    };
    exports.IllegalArgumentError = IllegalArgumentError;
    function constructErrorMessage(exceptionClass, message) {
      return `[VertexAI.${exceptionClass}]: ${message}`;
    }
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/post_fetch_processing.js
var require_post_fetch_processing = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/post_fetch_processing.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.processCountTokenResponse = exports.processUnary = exports.aggregateResponses = exports.processStream = exports.throwErrorIfNotOK = void 0;
    var util_1 = require_util();
    var errors_1 = require_errors();
    async function throwErrorIfNotOK(response) {
      if (response === void 0) {
        throw new errors_1.GoogleGenerativeAIError("response is undefined");
      }
      if (!response.ok) {
        const status = response.status;
        const statusText = response.statusText;
        const errorBody = await response.json();
        const errorMessage = `got status: ${status} ${statusText}. ${JSON.stringify(errorBody)}`;
        if (status >= 400 && status < 500) {
          const error = new errors_1.ClientError(errorMessage, new errors_1.GoogleApiError(errorBody.error.message, errorBody.error.code, errorBody.error.status, errorBody.error.details));
          throw error;
        }
        throw new errors_1.GoogleGenerativeAIError(errorMessage);
      }
    }
    exports.throwErrorIfNotOK = throwErrorIfNotOK;
    var responseLineRE = /^data: (.*)(?:\n\n|\r\r|\r\n\r\n)/;
    async function* generateResponseSequence(stream) {
      const reader = stream.getReader();
      while (true) {
        const { value, done } = await reader.read();
        if (done) {
          break;
        }
        yield addMissingIndexAndRole(value);
      }
    }
    async function processStream(response) {
      if (response === void 0) {
        throw new errors_1.GoogleGenerativeAIError("Error processing stream because response === undefined");
      }
      if (!response.body) {
        throw new errors_1.GoogleGenerativeAIError("Error processing stream because response.body not found");
      }
      const inputStream = response.body.pipeThrough(new TextDecoderStream("utf8", { fatal: true }));
      const responseStream = getResponseStream(inputStream);
      const [stream1, stream2] = responseStream.tee();
      return Promise.resolve({
        stream: generateResponseSequence(stream1),
        response: getResponsePromise(stream2)
      });
    }
    exports.processStream = processStream;
    async function getResponsePromise(stream) {
      const allResponses = [];
      const reader = stream.getReader();
      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          return aggregateResponses(allResponses);
        }
        allResponses.push(value);
      }
    }
    function getResponseStream(inputStream) {
      const reader = inputStream.getReader();
      const stream = new ReadableStream({
        start(controller) {
          let currentText = "";
          return pump();
          function pump() {
            return reader.read().then(({ value, done }) => {
              if (done) {
                if (currentText.trim()) {
                  controller.error(new errors_1.GoogleGenerativeAIError(`Failed to parse final chunk of stream: ${currentText}`));
                  return;
                }
                controller.close();
                return;
              }
              currentText += value;
              let match = currentText.match(responseLineRE);
              let parsedResponse;
              while (match) {
                try {
                  parsedResponse = JSON.parse(match[1]);
                } catch (e) {
                  controller.error(new errors_1.GoogleGenerativeAIError(`Error parsing JSON response from stream chunk: "${match[1]}"`));
                  return;
                }
                controller.enqueue(parsedResponse);
                currentText = currentText.substring(match[0].length);
                match = currentText.match(responseLineRE);
              }
              return pump();
            });
          }
        }
      });
      return stream;
    }
    function aggregateResponses(responses) {
      var _a, _b, _c;
      const lastResponse = responses[responses.length - 1];
      if (lastResponse === void 0) {
        throw new errors_1.GoogleGenerativeAIError("Error aggregating stream chunks because the final response in stream chunk is undefined");
      }
      const aggregatedResponse = {};
      if (lastResponse.promptFeedback) {
        aggregatedResponse.promptFeedback = lastResponse.promptFeedback;
      }
      if (lastResponse.usageMetadata) {
        aggregatedResponse.usageMetadata = lastResponse.usageMetadata;
      }
      for (const response of responses) {
        if (!response.candidates || response.candidates.length === 0) {
          continue;
        }
        for (let i = 0; i < response.candidates.length; i++) {
          if (!aggregatedResponse.candidates) {
            aggregatedResponse.candidates = [];
          }
          if (!aggregatedResponse.candidates[i]) {
            aggregatedResponse.candidates[i] = {
              index: (_a = response.candidates[i].index) !== null && _a !== void 0 ? _a : i,
              content: {
                role: (_c = (_b = response.candidates[i].content) === null || _b === void 0 ? void 0 : _b.role) !== null && _c !== void 0 ? _c : util_1.constants.MODEL_ROLE,
                parts: [{ text: "" }]
              }
            };
          }
          const citationMetadataAggregated = aggregateCitationMetadataForCandidate(response.candidates[i], aggregatedResponse.candidates[i]);
          if (citationMetadataAggregated) {
            aggregatedResponse.candidates[i].citationMetadata = citationMetadataAggregated;
          }
          const finishResonOfChunk = response.candidates[i].finishReason;
          if (finishResonOfChunk) {
            aggregatedResponse.candidates[i].finishReason = response.candidates[i].finishReason;
          }
          const finishMessageOfChunk = response.candidates[i].finishMessage;
          if (finishMessageOfChunk) {
            aggregatedResponse.candidates[i].finishMessage = finishMessageOfChunk;
          }
          const safetyRatingsOfChunk = response.candidates[i].safetyRatings;
          if (safetyRatingsOfChunk) {
            aggregatedResponse.candidates[i].safetyRatings = safetyRatingsOfChunk;
          }
          if (response.candidates[i].content && response.candidates[i].content.parts && response.candidates[i].content.parts.length > 0) {
            for (const part of response.candidates[i].content.parts) {
              if (part.text) {
                aggregatedResponse.candidates[i].content.parts[0].text += part.text;
              }
              if (part.functionCall) {
                aggregatedResponse.candidates[i].content.parts[0].functionCall = part.functionCall;
                delete aggregatedResponse.candidates[i].content.parts[0].text;
              }
            }
          }
          const groundingMetadataAggregated = aggregateGroundingMetadataForCandidate(response.candidates[i], aggregatedResponse.candidates[i]);
          if (groundingMetadataAggregated) {
            aggregatedResponse.candidates[i].groundingMetadata = groundingMetadataAggregated;
          }
        }
      }
      return aggregatedResponse;
    }
    exports.aggregateResponses = aggregateResponses;
    function aggregateCitationMetadataForCandidate(candidateChunk, aggregatedCandidate) {
      var _a;
      if (!candidateChunk.citationMetadata) {
        return;
      }
      const emptyCitationMetadata = {
        citations: []
      };
      const citationMetadataAggregated = (_a = aggregatedCandidate.citationMetadata) !== null && _a !== void 0 ? _a : emptyCitationMetadata;
      const citationMetadataChunk = candidateChunk.citationMetadata;
      if (citationMetadataChunk.citations) {
        citationMetadataAggregated.citations = citationMetadataAggregated.citations.concat(citationMetadataChunk.citations);
      }
      return citationMetadataAggregated;
    }
    function aggregateGroundingMetadataForCandidate(candidateChunk, aggregatedCandidate) {
      var _a;
      if (!candidateChunk.groundingMetadata) {
        return;
      }
      const emptyGroundingMetadata = {
        webSearchQueries: [],
        retrievalQueries: [],
        groundingChunks: [],
        groundingSupports: []
      };
      const groundingMetadataAggregated = (_a = aggregatedCandidate.groundingMetadata) !== null && _a !== void 0 ? _a : emptyGroundingMetadata;
      const groundingMetadataChunk = candidateChunk.groundingMetadata;
      if (groundingMetadataChunk.webSearchQueries) {
        groundingMetadataAggregated.webSearchQueries = groundingMetadataAggregated.webSearchQueries.concat(groundingMetadataChunk.webSearchQueries);
      }
      if (groundingMetadataChunk.retrievalQueries) {
        groundingMetadataAggregated.retrievalQueries = groundingMetadataAggregated.retrievalQueries.concat(groundingMetadataChunk.retrievalQueries);
      }
      if (groundingMetadataChunk.groundingChunks) {
        groundingMetadataAggregated.groundingChunks = groundingMetadataAggregated.groundingChunks.concat(groundingMetadataChunk.groundingChunks);
      }
      if (groundingMetadataChunk.groundingSupports) {
        groundingMetadataAggregated.groundingSupports = groundingMetadataAggregated.groundingSupports.concat(groundingMetadataChunk.groundingSupports);
      }
      if (groundingMetadataChunk.searchEntryPoint) {
        groundingMetadataAggregated.searchEntryPoint = groundingMetadataChunk.searchEntryPoint;
      }
      return groundingMetadataAggregated;
    }
    function addMissingIndexAndRole(response) {
      const generateContentResponse = response;
      if (generateContentResponse.candidates && generateContentResponse.candidates.length > 0) {
        generateContentResponse.candidates.forEach((candidate, index) => {
          if (candidate.index === void 0) {
            generateContentResponse.candidates[index].index = index;
          }
          if (candidate.content === void 0) {
            generateContentResponse.candidates[index].content = {};
          }
          if (candidate.content.role === void 0) {
            generateContentResponse.candidates[index].content.role = util_1.constants.MODEL_ROLE;
          }
        });
      }
      return generateContentResponse;
    }
    async function processUnary(response) {
      if (response !== void 0) {
        const responseJson = await response.json();
        const generateContentResponse = addMissingIndexAndRole(responseJson);
        return Promise.resolve({
          response: generateContentResponse
        });
      }
      return Promise.resolve({
        response: {}
      });
    }
    exports.processUnary = processUnary;
    async function processCountTokenResponse(response) {
      if (response) {
        return response.json();
      }
      return Promise.resolve({});
    }
    exports.processCountTokenResponse = processCountTokenResponse;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/post_request.js
var require_post_request = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/post_request.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.postRequest = void 0;
    var API_BASE_PATH = "aiplatform.googleapis.com";
    var GOOGLE_INTERNAL_ENDPOINT = "googleapis.com";
    var AUTHORIZATION_HEADER = "Authorization";
    var CONTENT_TYPE_HEADER = "Content-Type";
    var USER_AGENT_HEADER = "User-Agent";
    var X_GOOG_API_CLIENT_HEADER = "X-Goog-Api-Client";
    var SERVER_RESERVED_HEADERS = [AUTHORIZATION_HEADER, CONTENT_TYPE_HEADER];
    var errors_1 = require_errors();
    var constants = require_constants();
    async function postRequest({ region, resourcePath, resourceMethod, token, data, apiEndpoint, requestOptions, apiVersion = "v1" }) {
      const vertexBaseEndpoint = apiEndpoint !== null && apiEndpoint !== void 0 ? apiEndpoint : `${region}-${API_BASE_PATH}`;
      let vertexEndpoint = `https://${vertexBaseEndpoint}/${apiVersion}/${resourcePath}:${resourceMethod}`;
      if (resourceMethod === constants.STREAMING_GENERATE_CONTENT_METHOD) {
        vertexEndpoint += "?alt=sse";
      }
      const necessaryHeaders = new Headers({
        [AUTHORIZATION_HEADER]: `Bearer ${token}`,
        [CONTENT_TYPE_HEADER]: "application/json",
        [USER_AGENT_HEADER]: constants.USER_AGENT
      });
      const totalHeaders = getExtraHeaders(vertexBaseEndpoint, necessaryHeaders, requestOptions);
      return fetch(vertexEndpoint, {
        ...getFetchOptions(requestOptions),
        method: "POST",
        headers: totalHeaders,
        body: JSON.stringify(data)
      });
    }
    exports.postRequest = postRequest;
    function getFetchOptions(requestOptions) {
      const fetchOptions = {};
      if (!requestOptions || requestOptions.timeout === void 0 || requestOptions.timeout < 0) {
        return fetchOptions;
      }
      const abortController = new AbortController();
      const signal = abortController.signal;
      setTimeout(() => abortController.abort(), requestOptions.timeout);
      fetchOptions.signal = signal;
      return fetchOptions;
    }
    function stringHasLineBreak(header) {
      if (header === null || header === void 0) {
        return false;
      }
      return header.includes("\n") || header.includes("\r");
    }
    function headersHasLineBreak(customHeaders) {
      if (!customHeaders) {
        return false;
      }
      for (const [key, value] of customHeaders.entries()) {
        if (stringHasLineBreak(key) || stringHasLineBreak(value)) {
          return true;
        }
      }
      return false;
    }
    function getExtraHeaders(vertexBaseEndpoint, necessaryHeaders, requestOptions) {
      var _a;
      if (stringHasLineBreak(requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient)) {
        throw new errors_1.ClientError("Found line break in apiClient request option field, please remove the line break and try again.");
      }
      if (headersHasLineBreak(requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.customHeaders)) {
        throw new errors_1.ClientError("Found line break in customerHeaders request option field, please remove the line break and try again.");
      }
      const totalHeaders = new Headers(necessaryHeaders);
      const customHeaders = (_a = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.customHeaders) !== null && _a !== void 0 ? _a : new Headers();
      for (const [key, val] of customHeaders.entries()) {
        totalHeaders.append(key, val);
      }
      if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient) {
        totalHeaders.append(X_GOOG_API_CLIENT_HEADER, requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient);
      }
      let goldenHeaders;
      if (vertexBaseEndpoint.endsWith(GOOGLE_INTERNAL_ENDPOINT)) {
        goldenHeaders = necessaryHeaders;
      } else {
        goldenHeaders = customHeaders;
      }
      for (const header of SERVER_RESERVED_HEADERS) {
        if (goldenHeaders.has(header)) {
          totalHeaders.set(header, goldenHeaders.get(header));
        }
      }
      return totalHeaders;
    }
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/pre_fetch_processing.js
var require_pre_fetch_processing = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/pre_fetch_processing.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.hasVertexAISearch = exports.hasVertexRagStore = exports.getApiVersion = exports.validateGenerationConfig = exports.validateGenerateContentRequest = exports.formatContentRequest = void 0;
    var errors_1 = require_errors();
    var constants = require_constants();
    function formatContentRequest(request, generationConfig, safetySettings) {
      if (typeof request === "string") {
        return {
          contents: [{ role: constants.USER_ROLE, parts: [{ text: request }] }],
          generationConfig,
          safetySettings
        };
      } else {
        return request;
      }
    }
    exports.formatContentRequest = formatContentRequest;
    function validateGenerateContentRequest(request) {
      if (hasVertexAISearch(request) && hasVertexRagStore(request)) {
        throw new errors_1.ClientError("Found both vertexAiSearch and vertexRagStore field are set in tool. Either set vertexAiSearch or vertexRagStore.");
      }
    }
    exports.validateGenerateContentRequest = validateGenerateContentRequest;
    function validateGenerationConfig(generationConfig) {
      if ("topK" in generationConfig) {
        if (!(generationConfig.topK > 0) || !(generationConfig.topK <= 40)) {
          delete generationConfig.topK;
        }
      }
      return generationConfig;
    }
    exports.validateGenerationConfig = validateGenerationConfig;
    function getApiVersion(request) {
      return hasVertexRagStore(request) || hasCachedContent(request) ? "v1beta1" : "v1";
    }
    exports.getApiVersion = getApiVersion;
    function hasVertexRagStore(request) {
      var _a;
      for (const tool of (_a = request === null || request === void 0 ? void 0 : request.tools) !== null && _a !== void 0 ? _a : []) {
        const retrieval = tool.retrieval;
        if (!retrieval)
          continue;
        if (retrieval.vertexRagStore) {
          return true;
        }
      }
      return false;
    }
    exports.hasVertexRagStore = hasVertexRagStore;
    function hasCachedContent(request) {
      return !!request.cachedContent;
    }
    function hasVertexAISearch(request) {
      var _a;
      for (const tool of (_a = request === null || request === void 0 ? void 0 : request.tools) !== null && _a !== void 0 ? _a : []) {
        const retrieval = tool.retrieval;
        if (!retrieval)
          continue;
        if (retrieval.vertexAiSearch) {
          return true;
        }
      }
      return false;
    }
    exports.hasVertexAISearch = hasVertexAISearch;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/generate_content.js
var require_generate_content = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/generate_content.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.generateContentStream = exports.generateContent = void 0;
    var errors_1 = require_errors();
    var constants = require_constants();
    var post_fetch_processing_1 = require_post_fetch_processing();
    var post_request_1 = require_post_request();
    var pre_fetch_processing_1 = require_pre_fetch_processing();
    async function generateContent(location, resourcePath, token, request, apiEndpoint, generationConfig, safetySettings, tools, toolConfig, requestOptions) {
      var _a, _b, _c, _d;
      request = (0, pre_fetch_processing_1.formatContentRequest)(request, generationConfig, safetySettings);
      (0, pre_fetch_processing_1.validateGenerateContentRequest)(request);
      if (request.generationConfig) {
        request.generationConfig = (0, pre_fetch_processing_1.validateGenerationConfig)(request.generationConfig);
      }
      const generateContentRequest = {
        contents: request.contents,
        systemInstruction: request.systemInstruction,
        cachedContent: request.cachedContent,
        generationConfig: (_a = request.generationConfig) !== null && _a !== void 0 ? _a : generationConfig,
        safetySettings: (_b = request.safetySettings) !== null && _b !== void 0 ? _b : safetySettings,
        tools: (_c = request.tools) !== null && _c !== void 0 ? _c : tools,
        toolConfig: (_d = request.toolConfig) !== null && _d !== void 0 ? _d : toolConfig
      };
      const response = await (0, post_request_1.postRequest)({
        region: location,
        resourcePath,
        resourceMethod: constants.GENERATE_CONTENT_METHOD,
        token: await token,
        data: generateContentRequest,
        apiEndpoint,
        requestOptions,
        apiVersion: (0, pre_fetch_processing_1.getApiVersion)(request)
      }).catch((e) => {
        throw new errors_1.GoogleGenerativeAIError("exception posting request to model", e);
      });
      await (0, post_fetch_processing_1.throwErrorIfNotOK)(response).catch((e) => {
        throw e;
      });
      return (0, post_fetch_processing_1.processUnary)(response);
    }
    exports.generateContent = generateContent;
    async function generateContentStream(location, resourcePath, token, request, apiEndpoint, generationConfig, safetySettings, tools, toolConfig, requestOptions) {
      var _a, _b, _c, _d;
      request = (0, pre_fetch_processing_1.formatContentRequest)(request, generationConfig, safetySettings);
      (0, pre_fetch_processing_1.validateGenerateContentRequest)(request);
      if (request.generationConfig) {
        request.generationConfig = (0, pre_fetch_processing_1.validateGenerationConfig)(request.generationConfig);
      }
      const generateContentRequest = {
        contents: request.contents,
        systemInstruction: request.systemInstruction,
        cachedContent: request.cachedContent,
        generationConfig: (_a = request.generationConfig) !== null && _a !== void 0 ? _a : generationConfig,
        safetySettings: (_b = request.safetySettings) !== null && _b !== void 0 ? _b : safetySettings,
        tools: (_c = request.tools) !== null && _c !== void 0 ? _c : tools,
        toolConfig: (_d = request.toolConfig) !== null && _d !== void 0 ? _d : toolConfig
      };
      const response = await (0, post_request_1.postRequest)({
        region: location,
        resourcePath,
        resourceMethod: constants.STREAMING_GENERATE_CONTENT_METHOD,
        token: await token,
        data: generateContentRequest,
        apiEndpoint,
        requestOptions,
        apiVersion: (0, pre_fetch_processing_1.getApiVersion)(request)
      }).catch((e) => {
        throw new errors_1.GoogleGenerativeAIError("exception posting request", e);
      });
      await (0, post_fetch_processing_1.throwErrorIfNotOK)(response).catch((e) => {
        throw e;
      });
      return (0, post_fetch_processing_1.processStream)(response);
    }
    exports.generateContentStream = generateContentStream;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/models/chat_session.js
var require_chat_session = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/models/chat_session.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.ChatSessionPreview = exports.ChatSession = void 0;
    var util_1 = require_util2();
    var generate_content_1 = require_generate_content();
    var errors_1 = require_errors();
    var util_2 = require_util();
    var ChatSession = class {
      async getHistory() {
        return Promise.resolve(this.historyInternal);
      }
      /**
       * @constructor
       * @param request - {@link StartChatSessionRequest}
       */
      constructor(request, requestOptions) {
        var _a;
        this.sendStreamPromise = Promise.resolve();
        this.project = request.project;
        this.location = request.location;
        this.googleAuth = request.googleAuth;
        this.resourcePath = request.resourcePath;
        this.historyInternal = (_a = request.history) !== null && _a !== void 0 ? _a : [];
        this.generationConfig = request.generationConfig;
        this.safetySettings = request.safetySettings;
        this.tools = request.tools;
        this.toolConfig = request.toolConfig;
        this.apiEndpoint = request.apiEndpoint;
        this.requestOptions = requestOptions !== null && requestOptions !== void 0 ? requestOptions : {};
        if (request.systemInstruction) {
          this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(request.systemInstruction);
        }
      }
      /**
       * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
       * fails.
       * @returns Promise of token.
       */
      fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e) => {
          throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
      }
      /**
       * Makes an async call to send chat message.
       *
       * The response is returned in {@link
       * GenerateContentResult.response}.
       *
       * @example
       * ```
       * const chat = generativeModel.startChat();
       * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
       * console.log('Response: ', JSON.stringify(result1.response));
       *
       * const result2 = await chat.sendMessage("What about python?");
       * console.log('Response: ', JSON.stringify(result2.response));
       * ```
       *
       * @param request - send message request.
       * @returns Promise of {@link GenerateContentResult}.
       */
      async sendMessage(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentRequest = {
          contents: this.historyInternal.concat(newContent),
          safetySettings: this.safetySettings,
          generationConfig: this.generationConfig,
          tools: this.tools,
          toolConfig: this.toolConfig,
          systemInstruction: this.systemInstruction
        };
        const generateContentResult = await (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), generateContentRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e) => {
          throw e;
        });
        const generateContentResponse = await generateContentResult.response;
        if (generateContentResponse.candidates && generateContentResponse.candidates.length !== 0) {
          this.historyInternal = this.historyInternal.concat(newContent);
          const contentFromModel = generateContentResponse.candidates[0].content;
          this.historyInternal.push(contentFromModel);
        }
        return Promise.resolve(generateContentResult);
      }
      async appendHistory(streamGenerateContentResultPromise, newContent) {
        const streamGenerateContentResult = await streamGenerateContentResultPromise;
        const streamGenerateContentResponse = await streamGenerateContentResult.response;
        if (streamGenerateContentResponse.candidates && streamGenerateContentResponse.candidates.length !== 0) {
          this.historyInternal = this.historyInternal.concat(newContent);
          const contentFromModel = streamGenerateContentResponse.candidates[0].content;
          this.historyInternal.push(contentFromModel);
        }
      }
      /**
       * Makes an async call to stream send message.
       *
       * The response is streamed chunk by chunk in
       * {@link StreamGenerateContentResult.stream}. The aggregated response is
       * avaliable in {@link StreamGenerateContentResult.response} after all chunks
       * are returned.
       *
       * @example
       * ```
       * const chat = generativeModel.startChat();
       * const chatInput = "How can I learn more about Node.js?";
       * const result = await chat.sendMessageStream(chatInput);
       * for await (const item of result.stream) {
       *   console.log(item.candidates[0].content.parts[0].text);
       * }
       * const response = await result.response;
       * console.log('aggregated response: ', JSON.stringify(result.response));
       * ```
       *
       * @param request - send message request.
       * @returns Promise of {@link StreamGenerateContentResult}.
       */
      async sendMessageStream(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentrequest = {
          contents: this.historyInternal.concat(newContent),
          safetySettings: this.safetySettings,
          generationConfig: this.generationConfig,
          tools: this.tools,
          toolConfig: this.toolConfig,
          systemInstruction: this.systemInstruction
        };
        const streamGenerateContentResultPromise = (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), generateContentrequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e) => {
          throw e;
        });
        this.sendStreamPromise = this.appendHistory(streamGenerateContentResultPromise, newContent).catch((e) => {
          console.error(e);
        });
        return streamGenerateContentResultPromise;
      }
    };
    exports.ChatSession = ChatSession;
    var ChatSessionPreview = class {
      async getHistory() {
        return Promise.resolve(this.historyInternal);
      }
      /**
       * @constructor
       * @param request - {@link StartChatSessionRequest}
       */
      constructor(request, requestOptions) {
        var _a;
        this.sendStreamPromise = Promise.resolve();
        this.project = request.project;
        this.location = request.location;
        this.googleAuth = request.googleAuth;
        this.resourcePath = request.resourcePath;
        this.historyInternal = (_a = request.history) !== null && _a !== void 0 ? _a : [];
        this.generationConfig = request.generationConfig;
        this.safetySettings = request.safetySettings;
        this.tools = request.tools;
        this.toolConfig = request.toolConfig;
        this.apiEndpoint = request.apiEndpoint;
        this.requestOptions = requestOptions !== null && requestOptions !== void 0 ? requestOptions : {};
        this.cachedContent = request.cachedContent;
        if (request.systemInstruction) {
          this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(request.systemInstruction);
        }
      }
      /**
       * Gets access token from GoogleAuth. Throws GoogleAuthError when fails.
       * @returns Promise of token.
       */
      fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e) => {
          throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
      }
      /**
       * Makes an async call to send chat message.
       *
       * The response is returned in {@link
       * GenerateContentResult.response}.
       *
       * @example
       * ```
       * const chat = generativeModelPreview.startChat();
       * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
       * console.log('Response: ', JSON.stringify(result1.response));
       *
       * const result2 = await chat.sendMessage("What about python?");
       * console.log('Response: ', JSON.stringify(result2.response));
       * ```
       *
       * @param request - send message request.
       * @returns Promise of {@link GenerateContentResult}.
       */
      async sendMessage(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentRequest = {
          contents: this.historyInternal.concat(newContent),
          safetySettings: this.safetySettings,
          generationConfig: this.generationConfig,
          tools: this.tools,
          toolConfig: this.toolConfig,
          systemInstruction: this.systemInstruction,
          cachedContent: this.cachedContent
        };
        const generateContentResult = await (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), generateContentRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e) => {
          throw e;
        });
        const generateContentResponse = await generateContentResult.response;
        if (generateContentResponse.candidates && generateContentResponse.candidates.length !== 0) {
          this.historyInternal = this.historyInternal.concat(newContent);
          const contentFromAssistant = generateContentResponse.candidates[0].content;
          this.historyInternal.push(contentFromAssistant);
        }
        return Promise.resolve(generateContentResult);
      }
      async appendHistory(streamGenerateContentResultPromise, newContent) {
        const streamGenerateContentResult = await streamGenerateContentResultPromise;
        const streamGenerateContentResponse = await streamGenerateContentResult.response;
        if (streamGenerateContentResponse.candidates && streamGenerateContentResponse.candidates.length !== 0) {
          this.historyInternal = this.historyInternal.concat(newContent);
          const contentFromAssistant = streamGenerateContentResponse.candidates[0].content;
          this.historyInternal.push(contentFromAssistant);
        }
      }
      /**
       * Makes an async call to stream send message.
       *
       * The response is streamed chunk by chunk in
       * {@link StreamGenerateContentResult.stream}. The aggregated response is
       * avaliable in {@link StreamGenerateContentResult.response} after all chunks
       * are returned.
       *
       * @example
       * ```
       * const chat = generativeModel.startChat();
       * const chatInput = "How can I learn more about Node.js?";
       * const result = await chat.sendMessageStream(chatInput);
       * for await (const item of result.stream) {
       *   console.log(item.candidates[0].content.parts[0].text);
       * }
       * const response = await result.response;
       * console.log('aggregated response: ', JSON.stringify(result.response));
       * ```
       *
       * @param request - send message request.
       * @returns Promise of {@link StreamGenerateContentResult}.
       */
      async sendMessageStream(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentRequest = {
          contents: this.historyInternal.concat(newContent),
          safetySettings: this.safetySettings,
          generationConfig: this.generationConfig,
          tools: this.tools,
          toolConfig: this.toolConfig,
          systemInstruction: this.systemInstruction,
          cachedContent: this.cachedContent
        };
        const streamGenerateContentResultPromise = (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), generateContentRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e) => {
          throw e;
        });
        this.sendStreamPromise = this.appendHistory(streamGenerateContentResultPromise, newContent).catch((e) => {
          console.error(e);
        });
        return streamGenerateContentResultPromise;
      }
    };
    exports.ChatSessionPreview = ChatSessionPreview;
    function formulateNewContentFromSendMessageRequest(request) {
      let newParts = [];
      if (typeof request === "string") {
        newParts = [{ text: request }];
      } else if (Array.isArray(request)) {
        for (const item of request) {
          if (typeof item === "string") {
            newParts.push({ text: item });
          } else {
            newParts.push(item);
          }
        }
      }
      return assignRoleToPartsAndValidateSendMessageRequest(newParts);
    }
    function assignRoleToPartsAndValidateSendMessageRequest(parts) {
      const userContent = { role: util_2.constants.USER_ROLE, parts: [] };
      const functionContent = { role: util_2.constants.USER_ROLE, parts: [] };
      let hasUserContent = false;
      let hasFunctionContent = false;
      for (const part of parts) {
        if ("functionResponse" in part) {
          functionContent.parts.push(part);
          hasFunctionContent = true;
        } else {
          userContent.parts.push(part);
          hasUserContent = true;
        }
      }
      if (hasUserContent && hasFunctionContent) {
        throw new errors_1.ClientError("Within a single message, FunctionResponse cannot be mixed with other type of part in the request for sending chat message.");
      }
      if (!hasUserContent && !hasFunctionContent) {
        throw new errors_1.ClientError("No content is provided for sending chat message.");
      }
      if (hasUserContent) {
        return [userContent];
      }
      return [functionContent];
    }
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/count_tokens.js
var require_count_tokens = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/functions/count_tokens.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.countTokens = void 0;
    var errors_1 = require_errors();
    var constants = require_constants();
    var post_fetch_processing_1 = require_post_fetch_processing();
    var post_request_1 = require_post_request();
    async function countTokens(location, resourcePath, token, request, apiEndpoint, requestOptions) {
      const response = await (0, post_request_1.postRequest)({
        region: location,
        resourcePath,
        resourceMethod: constants.COUNT_TOKENS_METHOD,
        token: await token,
        data: request,
        apiEndpoint,
        requestOptions
      }).catch((e) => {
        throw new errors_1.GoogleGenerativeAIError("exception posting request", e);
      });
      await (0, post_fetch_processing_1.throwErrorIfNotOK)(response).catch((e) => {
        throw e;
      });
      return (0, post_fetch_processing_1.processCountTokenResponse)(response);
    }
    exports.countTokens = countTokens;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/models/generative_models.js
var require_generative_models = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/models/generative_models.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.GenerativeModelPreview = exports.GenerativeModel = void 0;
    var util_1 = require_util2();
    var count_tokens_1 = require_count_tokens();
    var generate_content_1 = require_generate_content();
    var errors_1 = require_errors();
    var util_2 = require_util();
    var chat_session_1 = require_chat_session();
    var GenerativeModel = class {
      /**
       * @constructor
       * @param getGenerativeModelParams - {@link GetGenerativeModelParams}
       */
      constructor(getGenerativeModelParams) {
        var _a;
        this.project = getGenerativeModelParams.project;
        this.location = getGenerativeModelParams.location;
        this.apiEndpoint = getGenerativeModelParams.apiEndpoint;
        this.googleAuth = getGenerativeModelParams.googleAuth;
        this.model = getGenerativeModelParams.model;
        this.generationConfig = getGenerativeModelParams.generationConfig;
        this.safetySettings = getGenerativeModelParams.safetySettings;
        this.tools = getGenerativeModelParams.tools;
        this.toolConfig = getGenerativeModelParams.toolConfig;
        this.requestOptions = (_a = getGenerativeModelParams.requestOptions) !== null && _a !== void 0 ? _a : {};
        if (getGenerativeModelParams.systemInstruction) {
          this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(getGenerativeModelParams.systemInstruction);
        }
        this.resourcePath = formulateResourcePathFromModel(this.model, this.project, this.location);
        this.publisherModelEndpoint = this.resourcePath;
      }
      /**
       * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
       * fails.
       * @returns Promise of token string.
       */
      fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e) => {
          throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
      }
      /**
       * Makes an async call to generate content.
       *
       * The response will be returned in {@link
       * GenerateContentResult.response}.
       *
       * @example
       * ```
       * const request = {
       *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
       * };
       * const result = await generativeModel.generateContent(request);
       * console.log('Response: ', JSON.stringify(result.response));
       * ```
       *
       * @param request - A GenerateContentRequest object with the request contents.
       * @returns The GenerateContentResponse object with the response candidates.
       */
      async generateContent(request) {
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction);
        return (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
      }
      /**
       * Makes an async stream request to generate content.
       *
       * The response is returned chunk by chunk as it's being generated in {@link
       * StreamGenerateContentResult.stream}. After all chunks of the response are
       * returned, the aggregated response is available in
       * {@link StreamGenerateContentResult.response}.
       *
       * @example
       * ```
       * const request = {
       *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
       * };
       * const streamingResult = await generativeModel.generateContentStream(request);
       * for await (const item of streamingResult.stream) {
       *   console.log('stream chunk: ', JSON.stringify(item));
       * }
       * const aggregatedResponse = await streamingResult.response;
       * console.log('aggregated response: ', JSON.stringify(aggregatedResponse));
       * ```
       *
       * @param request - {@link GenerateContentRequest}
       * @returns Promise of {@link StreamGenerateContentResult}
       */
      async generateContentStream(request) {
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction);
        return (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
      }
      /**
       * Makes an async request to count tokens.
       *
       * The `countTokens` function returns the token count and the number of
       * billable characters for a prompt.
       *
       * @example
       * ```
       * const request = {
       *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
       * };
       * const resp = await generativeModel.countTokens(request);
       * console.log('count tokens response: ', resp);
       * ```
       *
       * @param request - A CountTokensRequest object with the request contents.
       * @returns The CountTokensResponse object with the token count.
       */
      async countTokens(request) {
        return (0, count_tokens_1.countTokens)(this.location, this.resourcePath, this.fetchToken(), request, this.apiEndpoint, this.requestOptions);
      }
      /**
       * Instantiates a {@link ChatSession}.
       *
       * The {@link ChatSession} class is a stateful class that holds the state of
       * the conversation with the model and provides methods to interact with the
       * model in chat mode. Calling this method doesn't make any calls to a remote
       * endpoint. To make remote call, use {@link ChatSession.sendMessage} or
       * @link ChatSession.sendMessageStream}.
       *
       * @example
       * ```
       * const chat = generativeModel.startChat();
       * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
       * const response1 = await result1.response;
       * console.log('Response: ', JSON.stringify(response1));
       *
       * const result2 = await chat.sendMessageStream("What about python?");
       * const response2 = await result2.response;
       * console.log('Response: ', JSON.stringify(await response2));
       * ```
       *
       * @param request - {@link StartChatParams}
       * @returns {@link ChatSession}
       */
      startChat(request) {
        var _a, _b, _c, _d, _e, _f;
        const startChatRequest = {
          project: this.project,
          location: this.location,
          googleAuth: this.googleAuth,
          publisherModelEndpoint: this.publisherModelEndpoint,
          resourcePath: this.resourcePath,
          tools: this.tools,
          toolConfig: this.toolConfig,
          systemInstruction: this.systemInstruction
        };
        if (request) {
          startChatRequest.history = request.history;
          startChatRequest.generationConfig = (_a = request.generationConfig) !== null && _a !== void 0 ? _a : this.generationConfig;
          startChatRequest.safetySettings = (_b = request.safetySettings) !== null && _b !== void 0 ? _b : this.safetySettings;
          startChatRequest.tools = (_c = request.tools) !== null && _c !== void 0 ? _c : this.tools;
          startChatRequest.toolConfig = (_d = request.toolConfig) !== null && _d !== void 0 ? _d : this.toolConfig;
          startChatRequest.apiEndpoint = (_e = request.apiEndpoint) !== null && _e !== void 0 ? _e : this.apiEndpoint;
          startChatRequest.systemInstruction = (_f = request.systemInstruction) !== null && _f !== void 0 ? _f : this.systemInstruction;
        }
        return new chat_session_1.ChatSession(startChatRequest, this.requestOptions);
      }
    };
    exports.GenerativeModel = GenerativeModel;
    var GenerativeModelPreview = class {
      /**
       * @constructor
       * @param getGenerativeModelParams - {@link GetGenerativeModelParams}
       */
      constructor(getGenerativeModelParams) {
        var _a;
        this.project = getGenerativeModelParams.project;
        this.location = getGenerativeModelParams.location;
        this.apiEndpoint = getGenerativeModelParams.apiEndpoint;
        this.googleAuth = getGenerativeModelParams.googleAuth;
        this.model = getGenerativeModelParams.model;
        this.generationConfig = getGenerativeModelParams.generationConfig;
        this.safetySettings = getGenerativeModelParams.safetySettings;
        this.tools = getGenerativeModelParams.tools;
        this.toolConfig = getGenerativeModelParams.toolConfig;
        this.cachedContent = getGenerativeModelParams.cachedContent;
        this.requestOptions = (_a = getGenerativeModelParams.requestOptions) !== null && _a !== void 0 ? _a : {};
        if (getGenerativeModelParams.systemInstruction) {
          this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(getGenerativeModelParams.systemInstruction);
        }
        this.resourcePath = formulateResourcePathFromModel(this.model, this.project, this.location);
        this.publisherModelEndpoint = this.resourcePath;
      }
      /**
       * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
       * fails.
       * @returns Promise of token string.
       */
      fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e) => {
          throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
      }
      /**
       * Makes an async call to generate content.
       *
       * The response will be returned in {@link GenerateContentResult.response}.
       *
       * @example
       * ```
       * const request = {
       *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
       * };
       * const result = await generativeModelPreview.generateContent(request);
       * console.log('Response: ', JSON.stringify(result.response));
       * ```
       *
       * @param request - A GenerateContentRequest object with the request contents.
       * @returns The GenerateContentResponse object with the response candidates.
       */
      async generateContent(request) {
        var _a;
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = {
          ...formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction),
          cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name
        };
        return (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
      }
      /**
       * Makes an async stream request to generate content.
       *
       * The response is returned chunk by chunk as it's being generated in {@link
       * StreamGenerateContentResult.stream}. After all chunks of the response are
       * returned, the aggregated response is available in
       * {@link StreamGenerateContentResult.response}.
       *
       * @example
       * ```
       * const request = {
       *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
       * };
       * const streamingResult = await generativeModelPreview.generateContentStream(request);
       * for await (const item of streamingResult.stream) {
       *   console.log('stream chunk: ', JSON.stringify(item));
       * }
       * const aggregatedResponse = await streamingResult.response;
       * console.log('aggregated response: ', JSON.stringify(aggregatedResponse));
       * ```
       *
       * @param request - {@link GenerateContentRequest}
       * @returns Promise of {@link StreamGenerateContentResult}
       */
      async generateContentStream(request) {
        var _a;
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = {
          ...formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction),
          cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name
        };
        return (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
      }
      /**
       * Makes an async request to count tokens.
       *
       * The `countTokens` function returns the token count and the number of
       * billable characters for a prompt.
       *
       * @example
       * ```
       * const request = {
       *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
       * };
       * const resp = await generativeModelPreview.countTokens(request);
       * console.log('count tokens response: ', resp);
       * ```
       *
       * @param request - A CountTokensRequest object with the request contents.
       * @returns The CountTokensResponse object with the token count.
       */
      async countTokens(request) {
        return (0, count_tokens_1.countTokens)(this.location, this.resourcePath, this.fetchToken(), request, this.apiEndpoint, this.requestOptions);
      }
      /**
       * Instantiates a {@link ChatSessionPreview}.
       *
       * The {@link ChatSessionPreview} class is a stateful class that holds the state of
       * the conversation with the model and provides methods to interact with the
       * model in chat mode. Calling this method doesn't make any calls to a remote
       * endpoint. To make remote call, use {@link ChatSessionPreview.sendMessage} or
       * {@link ChatSessionPreview.sendMessageStream}.
       *
       * @example
       * ```
       * const chat = generativeModelPreview.startChat();
       * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
       * const response1 = await result1.response;
       * console.log('Response: ', JSON.stringify(response1));
       *
       * const result2 = await chat.sendMessageStream("What about python?");
       * const response2 = await result2.response;
       * console.log('Response: ', JSON.stringify(await response2));
       * ```
       *
       * @param request - {@link StartChatParams}
       * @returns {@link ChatSessionPreview}
       */
      startChat(request) {
        var _a, _b, _c, _d, _e, _f, _g, _h;
        const startChatRequest = {
          project: this.project,
          location: this.location,
          googleAuth: this.googleAuth,
          publisherModelEndpoint: this.publisherModelEndpoint,
          resourcePath: this.resourcePath,
          tools: this.tools,
          toolConfig: this.toolConfig,
          systemInstruction: this.systemInstruction,
          cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name
        };
        if (request) {
          startChatRequest.history = request.history;
          startChatRequest.generationConfig = (_b = request.generationConfig) !== null && _b !== void 0 ? _b : this.generationConfig;
          startChatRequest.safetySettings = (_c = request.safetySettings) !== null && _c !== void 0 ? _c : this.safetySettings;
          startChatRequest.tools = (_d = request.tools) !== null && _d !== void 0 ? _d : this.tools;
          startChatRequest.toolConfig = (_e = request.toolConfig) !== null && _e !== void 0 ? _e : this.toolConfig;
          startChatRequest.systemInstruction = (_f = request.systemInstruction) !== null && _f !== void 0 ? _f : this.systemInstruction;
          startChatRequest.cachedContent = (_g = request.cachedContent) !== null && _g !== void 0 ? _g : (_h = this.cachedContent) === null || _h === void 0 ? void 0 : _h.name;
        }
        return new chat_session_1.ChatSessionPreview(startChatRequest, this.requestOptions);
      }
      getModelName() {
        return this.model;
      }
      getCachedContent() {
        return this.cachedContent;
      }
      getSystemInstruction() {
        return this.systemInstruction;
      }
    };
    exports.GenerativeModelPreview = GenerativeModelPreview;
    function formulateResourcePathFromModel(model, project, location) {
      let resourcePath;
      if (!model) {
        throw new errors_1.ClientError("model parameter must not be empty.");
      }
      if (!model.includes("/")) {
        resourcePath = `projects/${project}/locations/${location}/publishers/google/models/${model}`;
      } else if (model.startsWith("models/")) {
        resourcePath = `projects/${project}/locations/${location}/publishers/google/${model}`;
      } else if (model.startsWith("projects/")) {
        resourcePath = model;
      } else {
        throw new errors_1.ClientError("model parameter must be either a Model Garden model ID or a full resource name.");
      }
      return resourcePath;
    }
    function formulateRequestToGenerateContentRequest(request) {
      if (typeof request === "string") {
        return {
          contents: [{ role: util_2.constants.USER_ROLE, parts: [{ text: request }] }]
        };
      }
      return request;
    }
    function formulateSystemInstructionIntoGenerateContentRequest(methodRequest, classSystemInstruction) {
      if (methodRequest.systemInstruction) {
        methodRequest.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(methodRequest.systemInstruction);
        return methodRequest;
      }
      if (classSystemInstruction) {
        methodRequest.systemInstruction = classSystemInstruction;
      }
      return methodRequest;
    }
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/models/index.js
var require_models = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/models/index.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.GenerativeModelPreview = exports.GenerativeModel = exports.ChatSessionPreview = exports.ChatSession = void 0;
    var chat_session_1 = require_chat_session();
    Object.defineProperty(exports, "ChatSession", { enumerable: true, get: function() {
      return chat_session_1.ChatSession;
    } });
    Object.defineProperty(exports, "ChatSessionPreview", { enumerable: true, get: function() {
      return chat_session_1.ChatSessionPreview;
    } });
    var generative_models_1 = require_generative_models();
    Object.defineProperty(exports, "GenerativeModel", { enumerable: true, get: function() {
      return generative_models_1.GenerativeModel;
    } });
    Object.defineProperty(exports, "GenerativeModelPreview", { enumerable: true, get: function() {
      return generative_models_1.GenerativeModelPreview;
    } });
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/common.js
var require_common = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/common.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.SchemaType = void 0;
    var SchemaType;
    (function(SchemaType2) {
      SchemaType2["STRING"] = "STRING";
      SchemaType2["NUMBER"] = "NUMBER";
      SchemaType2["INTEGER"] = "INTEGER";
      SchemaType2["BOOLEAN"] = "BOOLEAN";
      SchemaType2["ARRAY"] = "ARRAY";
      SchemaType2["OBJECT"] = "OBJECT";
    })(SchemaType || (exports.SchemaType = SchemaType = {}));
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/content.js
var require_content = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/content.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.FunctionDeclarationSchemaType = exports.Mode = exports.FinishReason = exports.BlockedReason = exports.HarmSeverity = exports.HarmProbability = exports.HarmBlockThreshold = exports.HarmCategory = void 0;
    var common_1 = require_common();
    var HarmCategory;
    (function(HarmCategory2) {
      HarmCategory2["HARM_CATEGORY_UNSPECIFIED"] = "HARM_CATEGORY_UNSPECIFIED";
      HarmCategory2["HARM_CATEGORY_HATE_SPEECH"] = "HARM_CATEGORY_HATE_SPEECH";
      HarmCategory2["HARM_CATEGORY_DANGEROUS_CONTENT"] = "HARM_CATEGORY_DANGEROUS_CONTENT";
      HarmCategory2["HARM_CATEGORY_HARASSMENT"] = "HARM_CATEGORY_HARASSMENT";
      HarmCategory2["HARM_CATEGORY_SEXUALLY_EXPLICIT"] = "HARM_CATEGORY_SEXUALLY_EXPLICIT";
    })(HarmCategory || (exports.HarmCategory = HarmCategory = {}));
    var HarmBlockThreshold;
    (function(HarmBlockThreshold2) {
      HarmBlockThreshold2["HARM_BLOCK_THRESHOLD_UNSPECIFIED"] = "HARM_BLOCK_THRESHOLD_UNSPECIFIED";
      HarmBlockThreshold2["BLOCK_LOW_AND_ABOVE"] = "BLOCK_LOW_AND_ABOVE";
      HarmBlockThreshold2["BLOCK_MEDIUM_AND_ABOVE"] = "BLOCK_MEDIUM_AND_ABOVE";
      HarmBlockThreshold2["BLOCK_ONLY_HIGH"] = "BLOCK_ONLY_HIGH";
      HarmBlockThreshold2["BLOCK_NONE"] = "BLOCK_NONE";
    })(HarmBlockThreshold || (exports.HarmBlockThreshold = HarmBlockThreshold = {}));
    var HarmProbability;
    (function(HarmProbability2) {
      HarmProbability2["HARM_PROBABILITY_UNSPECIFIED"] = "HARM_PROBABILITY_UNSPECIFIED";
      HarmProbability2["NEGLIGIBLE"] = "NEGLIGIBLE";
      HarmProbability2["LOW"] = "LOW";
      HarmProbability2["MEDIUM"] = "MEDIUM";
      HarmProbability2["HIGH"] = "HIGH";
    })(HarmProbability || (exports.HarmProbability = HarmProbability = {}));
    var HarmSeverity;
    (function(HarmSeverity2) {
      HarmSeverity2["HARM_SEVERITY_UNSPECIFIED"] = "HARM_SEVERITY_UNSPECIFIED";
      HarmSeverity2["HARM_SEVERITY_NEGLIGIBLE"] = "HARM_SEVERITY_NEGLIGIBLE";
      HarmSeverity2["HARM_SEVERITY_LOW"] = "HARM_SEVERITY_LOW";
      HarmSeverity2["HARM_SEVERITY_MEDIUM"] = "HARM_SEVERITY_MEDIUM";
      HarmSeverity2["HARM_SEVERITY_HIGH"] = "HARM_SEVERITY_HIGH";
    })(HarmSeverity || (exports.HarmSeverity = HarmSeverity = {}));
    var BlockedReason;
    (function(BlockedReason2) {
      BlockedReason2["BLOCKED_REASON_UNSPECIFIED"] = "BLOCK_REASON_UNSPECIFIED";
      BlockedReason2["SAFETY"] = "SAFETY";
      BlockedReason2["OTHER"] = "OTHER";
      BlockedReason2["BLOCKLIST"] = "BLOCKLIST";
      BlockedReason2["PROHIBITED_CONTENT"] = "PROHIBITED_CONTENT";
    })(BlockedReason || (exports.BlockedReason = BlockedReason = {}));
    var FinishReason;
    (function(FinishReason2) {
      FinishReason2["FINISH_REASON_UNSPECIFIED"] = "FINISH_REASON_UNSPECIFIED";
      FinishReason2["STOP"] = "STOP";
      FinishReason2["MAX_TOKENS"] = "MAX_TOKENS";
      FinishReason2["SAFETY"] = "SAFETY";
      FinishReason2["RECITATION"] = "RECITATION";
      FinishReason2["OTHER"] = "OTHER";
      FinishReason2["BLOCKLIST"] = "BLOCKLIST";
      FinishReason2["PROHIBITED_CONTENT"] = "PROHIBITED_CONTENT";
      FinishReason2["SPII"] = "SPII";
    })(FinishReason || (exports.FinishReason = FinishReason = {}));
    var Mode;
    (function(Mode2) {
      Mode2["MODE_UNSPECIFIED"] = "MODE_UNSPECIFIED";
      Mode2["MODE_DYNAMIC"] = "MODE_DYNAMIC";
    })(Mode || (exports.Mode = Mode = {}));
    exports.FunctionDeclarationSchemaType = { ...common_1.SchemaType };
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/tool.js
var require_tool = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/tool.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.FunctionCallingMode = void 0;
    var FunctionCallingMode;
    (function(FunctionCallingMode2) {
      FunctionCallingMode2["MODE_UNSPECIFIED"] = "MODE_UNSPECIFIED";
      FunctionCallingMode2["AUTO"] = "AUTO";
      FunctionCallingMode2["ANY"] = "ANY";
      FunctionCallingMode2["NONE"] = "NONE";
    })(FunctionCallingMode || (exports.FunctionCallingMode = FunctionCallingMode = {}));
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/generate_content_response_handler.js
var require_generate_content_response_handler = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/generate_content_response_handler.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.GenerateContentResponseHandler = void 0;
    var GenerateContentResponseHandler = class {
      /**
       * Extracts function calls from a {@link GenerateContentCandidate}.
       *
       * @param candidate - The candidate to extract function calls from.
       * @returns the array of function calls in a {@link GenerateContentCandidate}.
       */
      static getFunctionCallsFromCandidate(candidate) {
        if (!candidate)
          return [];
        return candidate.content.parts.filter((part) => !!part && !!part.functionCall).map((part) => part.functionCall);
      }
    };
    exports.GenerateContentResponseHandler = GenerateContentResponseHandler;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/index.js
var require_types = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/types/index.js"(exports) {
    "use strict";
    var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      var desc = Object.getOwnPropertyDescriptor(m, k);
      if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = { enumerable: true, get: function() {
          return m[k];
        } };
      }
      Object.defineProperty(o, k2, desc);
    } : function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    });
    var __exportStar = exports && exports.__exportStar || function(m, exports2) {
      for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p)) __createBinding(exports2, m, p);
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.GenerateContentResponseHandler = void 0;
    __exportStar(require_content(), exports);
    __exportStar(require_errors(), exports);
    __exportStar(require_tool(), exports);
    __exportStar(require_common(), exports);
    var generate_content_response_handler_1 = require_generate_content_response_handler();
    Object.defineProperty(exports, "GenerateContentResponseHandler", { enumerable: true, get: function() {
      return generate_content_response_handler_1.GenerateContentResponseHandler;
    } });
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/resources/cached_contents.js
var require_cached_contents = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/resources/cached_contents.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.CachedContents = exports.inferModelName = exports.inferFullResourceName = void 0;
    var util_1 = require_util2();
    var types_1 = require_types();
    function camelToSnake(str) {
      return str.replace(/[A-Z]/g, (letter) => `_${letter.toLowerCase()}`);
    }
    var CachedContentsClient = class {
      constructor(apiClient) {
        this.apiClient = apiClient;
      }
      create(cachedContent) {
        return this.apiClient.unaryApiCall(new URL(this.apiClient.getBaseUrl() + "/" + this.apiClient.getBaseResourePath() + "/cachedContents"), {
          body: JSON.stringify(cachedContent)
        }, "POST");
      }
      update(cachedContent, updateMask) {
        const url = new URL(this.apiClient.getBaseUrl() + "/" + cachedContent.name);
        url.searchParams.append("updateMask", updateMask.map((e) => camelToSnake(e)).join(","));
        return this.apiClient.unaryApiCall(url, {
          body: JSON.stringify(cachedContent)
        }, "PATCH");
      }
      delete(name) {
        return this.apiClient.unaryApiCall(new URL(this.apiClient.getBaseUrl() + "/" + name), {}, "DELETE");
      }
      list(pageSize, pageToken) {
        const url = new URL(this.apiClient.getBaseUrl() + "/" + this.apiClient.getBaseResourePath() + "/cachedContents");
        if (pageSize)
          url.searchParams.append("pageSize", String(pageSize));
        if (pageToken)
          url.searchParams.append("pageToken", pageToken);
        return this.apiClient.unaryApiCall(url, {}, "GET");
      }
      get(name) {
        return this.apiClient.unaryApiCall(new URL(this.apiClient.getBaseUrl() + "/" + name), {}, "GET");
      }
    };
    function inferFullResourceName(project, location, cachedContentId) {
      if (cachedContentId.startsWith("projects/")) {
        return cachedContentId;
      }
      if (cachedContentId.startsWith("locations/")) {
        return `projects/${project}/${cachedContentId}`;
      }
      if (cachedContentId.startsWith("cachedContents/")) {
        return `projects/${project}/locations/${location}/${cachedContentId}`;
      }
      if (!cachedContentId.includes("/")) {
        return `projects/${project}/locations/${location}/cachedContents/${cachedContentId}`;
      }
      throw new types_1.ClientError(`Invalid CachedContent.name: ${cachedContentId}. CachedContent.name should start with 'projects/', 'locations/', 'cachedContents/' or is a number type.`);
    }
    exports.inferFullResourceName = inferFullResourceName;
    function inferModelName(project, location, model) {
      if (!model) {
        throw new types_1.ClientError("Model name is required.");
      }
      if (model.startsWith("publishers/")) {
        return `projects/${project}/locations/${location}/${model}`;
      }
      if (!model.startsWith("projects/")) {
        return `projects/${project}/locations/${location}/publishers/google/models/${model}`;
      }
      return model;
    }
    exports.inferModelName = inferModelName;
    var CachedContents = class {
      constructor(client) {
        this.client = new CachedContentsClient(client);
      }
      /**
       * Creates cached content, this call will initialize the cached content in the data storage, and users need to pay for the cache data storage.
       * @param cachedContent
       * @param parent - Required. The parent resource where the cached content will be created.
       */
      create(cachedContent) {
        const curatedCachedContent = {
          ...cachedContent,
          systemInstruction: cachedContent.systemInstruction ? (0, util_1.formulateSystemInstructionIntoContent)(cachedContent.systemInstruction) : void 0,
          model: inferModelName(this.client.apiClient.project, this.client.apiClient.location, cachedContent.model)
        };
        return this.client.create(curatedCachedContent);
      }
      /**
       * Updates cached content configurations
       *
       * @param updateMask - Required. The list of fields to update. Format: google-fieldmask. See {@link https://cloud.google.com/docs/discovery/type-format}
       * @param name - Immutable. Identifier. The server-generated resource name of the cached content Format: projects/{project}/locations/{location}/cachedContents/{cached_content}.
       */
      update(cachedContent, updateMask) {
        if (!cachedContent.name) {
          throw new types_1.ClientError("Cached content name is required for update.");
        }
        if (!updateMask || updateMask.length === 0) {
          throw new types_1.ClientError('Update mask is required for update. Fields set in cachedContent but not in updateMask will be ignored. Examples: ["ttl"] or ["expireTime"].');
        }
        const curatedCachedContent = {
          ...cachedContent,
          systemInstruction: cachedContent.systemInstruction ? (0, util_1.formulateSystemInstructionIntoContent)(cachedContent.systemInstruction) : void 0,
          name: inferFullResourceName(this.client.apiClient.project, this.client.apiClient.location, cachedContent.name)
        };
        return this.client.update(curatedCachedContent, updateMask);
      }
      /**
       * Deletes cached content.
       *
       * @param name - Required. The resource name referring to the cached content.
       */
      delete(name) {
        return this.client.delete(inferFullResourceName(this.client.apiClient.project, this.client.apiClient.location, name));
      }
      /**
       * Lists cached contents in a project.
       *
       * @param pageSize - Optional. The maximum number of cached contents to return. The service may return fewer than this value. If unspecified, some default (under maximum) number of items will be returned. The maximum value is 1000; values above 1000 will be coerced to 1000.
       * @param pageToken - Optional. A page token, received from a previous `ListCachedContents` call. Provide this to retrieve the subsequent page. When paginating, all other parameters provided to `ListCachedContents` must match the call that provided the page token.
       */
      list(pageSize, pageToken) {
        return this.client.list(pageSize, pageToken);
      }
      /**
       * Gets cached content configurations.
       *
       * @param name - Required. The resource name referring to the cached content.
       */
      get(name) {
        return this.client.get(inferFullResourceName(this.client.apiClient.project, this.client.apiClient.location, name));
      }
    };
    exports.CachedContents = CachedContents;
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/resources/shared/api_client.js
var require_api_client = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/resources/shared/api_client.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.ApiClient = void 0;
    var util_1 = require_util();
    var types_1 = require_types();
    var AUTHORIZATION_HEADER = "Authorization";
    var CONTENT_TYPE_HEADER = "Content-Type";
    var USER_AGENT_HEADER = "User-Agent";
    var ApiClient = class {
      constructor(project, location, apiVersion, googleAuth) {
        this.project = project;
        this.location = location;
        this.apiVersion = apiVersion;
        this.googleAuth = googleAuth;
      }
      /**
       * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
       * fails.
       * @returns Promise of token string.
       */
      fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e) => {
          throw new types_1.GoogleAuthError(util_1.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
      }
      getBaseUrl() {
        return `https://${this.location}-aiplatform.googleapis.com/${this.apiVersion}`;
      }
      getBaseResourePath() {
        return `projects/${this.project}/locations/${this.location}`;
      }
      async unaryApiCall(url, requestInit, httpMethod) {
        const token = await this.getHeaders();
        return this.apiCall(url.toString(), {
          ...requestInit,
          method: httpMethod,
          headers: token
        });
      }
      async apiCall(url, requestInit) {
        const response = await fetch(url, requestInit).catch((e) => {
          throw new types_1.GoogleGenerativeAIError(`exception sending request to url: ${url} with requestInit: ${JSON.stringify(requestInit)}}`, e);
        });
        await throwErrorIfNotOK(response, url, requestInit).catch((e) => {
          throw e;
        });
        try {
          return await response.json();
        } catch (e) {
          throw new types_1.GoogleGenerativeAIError(JSON.stringify(response), e);
        }
      }
      async getHeaders() {
        const token = await this.fetchToken();
        return new Headers({
          [AUTHORIZATION_HEADER]: `Bearer ${token}`,
          [CONTENT_TYPE_HEADER]: "application/json",
          [USER_AGENT_HEADER]: util_1.constants.USER_AGENT
        });
      }
    };
    exports.ApiClient = ApiClient;
    async function throwErrorIfNotOK(response, url, requestInit) {
      var _a;
      if (response === void 0) {
        throw new types_1.GoogleGenerativeAIError("response is undefined");
      }
      if (!response.ok) {
        const status = response.status;
        const statusText = response.statusText;
        let errorBody;
        if ((_a = response.headers.get("content-type")) === null || _a === void 0 ? void 0 : _a.includes("application/json")) {
          errorBody = await response.json();
        } else {
          errorBody = {
            error: {
              message: `exception sending request to url: ${url} with requestInit: ${JSON.stringify(requestInit)}}`,
              code: response.status,
              status: response.statusText
            }
          };
        }
        const errorMessage = `got status: ${status} ${statusText}. ${JSON.stringify(errorBody)}`;
        if (status >= 400 && status < 500) {
          const error = new types_1.ClientError(errorMessage, new types_1.GoogleApiError(errorBody.error.message, errorBody.error.code, errorBody.error.status, errorBody.error.details));
          throw error;
        }
        throw new types_1.GoogleGenerativeAIError(errorMessage);
      }
    }
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/resources/index.js
var require_resources = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/resources/index.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.ApiClient = exports.CachedContents = void 0;
    var cached_contents_1 = require_cached_contents();
    Object.defineProperty(exports, "CachedContents", { enumerable: true, get: function() {
      return cached_contents_1.CachedContents;
    } });
    var api_client_1 = require_api_client();
    Object.defineProperty(exports, "ApiClient", { enumerable: true, get: function() {
      return api_client_1.ApiClient;
    } });
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/vertex_ai.js
var require_vertex_ai = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/vertex_ai.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.VertexAI = void 0;
    var google_auth_library_1 = require_src();
    var models_1 = require_models();
    var errors_1 = require_errors();
    var Resources = require_resources();
    var cached_contents_1 = require_cached_contents();
    var VertexAI = class {
      /**
         * @constructor
         * @param init - assign authentication related information,
         *     including the project and location strings, to instantiate a Vertex AI
         * client.
         * @throws {IllegalArgumentError}
      
         */
      constructor(init) {
        const opts = validateGoogleAuthOptions(init.project, init.googleAuthOptions);
        this.location = resolveLocation(init.location);
        this.project = resolveProject(init.project);
        this.googleAuth = new google_auth_library_1.GoogleAuth(opts);
        this.apiEndpoint = init.apiEndpoint;
        this.preview = new VertexAIPreview(this.project, this.location, this.googleAuth, this.apiEndpoint);
      }
      /**
       * Gets the GenerativeModel class instance.
       *
       * This method creates a new instance of the `GenerativeModel` class with the
       * platform initialization parameters provided in {@link VertexInit} and model
       * initialization parameters provided in {@link ModelParams}. You can
       * optionally provide {@link RequestOptions} to override the default request
       * options.
       *
       * @example
       * ```
       * const project = 'your-cloud-project';
       * const location = 'us-central1';
       * const textModel =  'gemini-1.0-pro';
       * const visionModel = 'gemini-1.0-pro-vision';
       *
       * const vertexAI = new VertexAI({project: project, location: location});
       *
       * // Instantiate models
       * const generativeModel = vertexAI.getGenerativeModel({
       *   model: textModel,
       *   // The following parameters are optional
       *   // They can also be passed to individual content generation requests
       *   safetySettings: [{
       *                      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
       *                      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
       *                     }],
       *   generationConfig: {maxOutputTokens: 256},
       * });
       *
       * const generativeVisionModel = vertexAI.getGenerativeModel({
       *   model: visionModel,
       * });
       *
       * const generativeModelPreview = vertexAI.preview.getGenerativeModel({
       *   model: textModel,
       * });
       * ```
       *
       * @param modelParams - {@link ModelParams} Parameters to
       *     specify the generative model.
       * @param requestOptions - {@link RequestOptions} Parameters to specify
       *     request options
       * @returns Instance of the GenerativeModel class.
       */
      getGenerativeModel(modelParams, requestOptions) {
        const getGenerativeModelParams = {
          model: modelParams.model,
          project: this.project,
          location: this.location,
          googleAuth: this.googleAuth,
          apiEndpoint: this.apiEndpoint,
          safetySettings: modelParams.safetySettings,
          generationConfig: modelParams.generationConfig,
          tools: modelParams.tools,
          toolConfig: modelParams.toolConfig,
          requestOptions,
          systemInstruction: modelParams.systemInstruction
        };
        return new models_1.GenerativeModel(getGenerativeModelParams);
      }
      getProject() {
        return this.project;
      }
      getLocation() {
        return this.location;
      }
    };
    exports.VertexAI = VertexAI;
    var VertexAIPreview = class {
      /**
       * @constructor
       * @param project - The Google Cloud project to use for the request
       * @param location - location The Google Cloud project location to use for the
       *     request
       * @param googleAuth - The GoogleAuthen class instance from
       *     google-auth-library.
       *        Complete list of authentication options is documented in the
       * GoogleAuthOptions interface:
       *        https://github.com/googleapis/google-auth-library-nodejs/blob/main/src/auth/googleauth.ts
       * @param apiEndpoint - [apiEndpoint] The base Vertex AI endpoint to use for
       *     the request. If
       *        not provided, the default regionalized endpoint
       *        (i.e. us-central1-aiplatform.googleapis.com) will be used.
       */
      constructor(project, location, googleAuth, apiEndpoint) {
        this.project = project;
        this.location = location;
        this.googleAuth = googleAuth;
        this.apiEndpoint = apiEndpoint;
        this.apiClient = new Resources.ApiClient(this.project, this.location, "v1beta1", this.googleAuth);
        this.cachedContents = new Resources.CachedContents(this.apiClient);
      }
      /**
       * @param modelParams - {@link ModelParams} Parameters to
       *     specify the generative model.
       * @returns Instance of the GenerativeModelPreview class.
       */
      getGenerativeModel(modelParams, requestOptions) {
        const getGenerativeModelParams = {
          model: modelParams.model,
          project: this.project,
          location: this.location,
          googleAuth: this.googleAuth,
          apiEndpoint: this.apiEndpoint,
          safetySettings: modelParams.safetySettings,
          generationConfig: modelParams.generationConfig,
          tools: modelParams.tools,
          toolConfig: modelParams.toolConfig,
          requestOptions,
          systemInstruction: modelParams.systemInstruction
        };
        return new models_1.GenerativeModelPreview(getGenerativeModelParams);
      }
      getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions) {
        if (!cachedContent.name) {
          throw new errors_1.ClientError("Cached content must contain a `name` field.");
        }
        if (!cachedContent.model) {
          throw new errors_1.ClientError("Cached content must contain a `model` field.");
        }
        validateCachedContentModel(cachedContent.model);
        const disallowedDuplicates = ["model", "systemInstruction"];
        for (const key of disallowedDuplicates) {
          if ((modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) && cachedContent[key] && (modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) !== cachedContent[key]) {
            if (key === "model") {
              const modelParamsComp = parseModelName(modelParams[key]);
              const cachedContentComp = parseModelName(cachedContent[key]);
              if (modelParamsComp === cachedContentComp) {
                continue;
              }
            }
            throw new errors_1.ClientError(`Different value for "${key}" specified in modelParams (${modelParams[key]}) and cachedContent (${cachedContent[key]})`);
          }
        }
        cachedContent.name = (0, cached_contents_1.inferFullResourceName)(this.project, this.location, cachedContent.name);
        const modelParamsFromCache = {
          model: cachedContent.model,
          project: this.project,
          location: this.location,
          googleAuth: this.googleAuth,
          apiEndpoint: this.apiEndpoint,
          safetySettings: modelParams === null || modelParams === void 0 ? void 0 : modelParams.safetySettings,
          generationConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.generationConfig,
          tools: cachedContent.tools,
          toolConfig: cachedContent.toolConfig,
          requestOptions,
          systemInstruction: cachedContent.systemInstruction,
          cachedContent
        };
        return new models_1.GenerativeModelPreview(modelParamsFromCache);
      }
    };
    function validateCachedContentModel(modelName) {
      if (modelName.startsWith("models/") || modelName.startsWith("projects/") && modelName.includes("/publishers/google/models/") || !modelName.includes("/")) {
        return;
      }
      throw new errors_1.ClientError(`Cached content model name must start with "models/" or match "projects/.*/publishers/google/models/.*" or is a model name listed at https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions. Received: ${modelName}`);
    }
    function parseModelName(modelName) {
      if (!modelName.includes("/")) {
        return modelName;
      }
      return modelName.split("/").pop();
    }
    function validateGoogleAuthOptions(project, googleAuthOptions) {
      let opts;
      const requiredScope = "https://www.googleapis.com/auth/cloud-platform";
      if (!googleAuthOptions) {
        opts = {
          scopes: requiredScope
        };
        return opts;
      }
      if (googleAuthOptions.projectId && googleAuthOptions.projectId !== project) {
        throw new Error(`inconsistent project ID values. argument project got value ${project} but googleAuthOptions.projectId got value ${googleAuthOptions.projectId}`);
      }
      opts = googleAuthOptions;
      if (!opts.scopes) {
        opts.scopes = requiredScope;
        return opts;
      }
      if (typeof opts.scopes === "string" && opts.scopes !== requiredScope || Array.isArray(opts.scopes) && opts.scopes.indexOf(requiredScope) < 0) {
        throw new errors_1.GoogleAuthError(`input GoogleAuthOptions.scopes ${opts.scopes} doesn't contain required scope ${requiredScope}, please include ${requiredScope} into GoogleAuthOptions.scopes or leave GoogleAuthOptions.scopes undefined`);
      }
      return opts;
    }
    function resolveProject(projectFromInput) {
      const projectNotFoundErrorMessage = "Unable to infer your project.Please provide a project Id by one of the following:\n- Passing a constructor argument by using new VertexAI({project: my-project})\n- Setting project using `gcloud config set project my-project`";
      if (projectFromInput) {
        return projectFromInput;
      }
      const inferredProjectFromEnv = process.env["GOOGLE_CLOUD_PROJECT"];
      if (inferredProjectFromEnv) {
        return inferredProjectFromEnv;
      }
      throw new errors_1.IllegalArgumentError(projectNotFoundErrorMessage);
    }
    function resolveLocation(locationFromInput) {
      if (locationFromInput) {
        return locationFromInput;
      }
      const inferredLocation = process.env["GOOGLE_CLOUD_REGION"] || process.env["CLOUD_ML_REGION"];
      if (inferredLocation) {
        return inferredLocation;
      }
      return "us-central1";
    }
  }
});

// node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/index.js
var require_src2 = __commonJS({
  "node_modules/.pnpm/@google-cloud+vertexai@1.9.3/node_modules/@google-cloud/vertexai/build/src/index.js"(exports) {
    var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      var desc = Object.getOwnPropertyDescriptor(m, k);
      if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = { enumerable: true, get: function() {
          return m[k];
        } };
      }
      Object.defineProperty(o, k2, desc);
    } : function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    });
    var __exportStar = exports && exports.__exportStar || function(m, exports2) {
      for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p)) __createBinding(exports2, m, p);
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.VertexAI = void 0;
    var vertex_ai_1 = require_vertex_ai();
    Object.defineProperty(exports, "VertexAI", { enumerable: true, get: function() {
      return vertex_ai_1.VertexAI;
    } });
    __exportStar(require_types(), exports);
    __exportStar(require_models(), exports);
  }
});
export default require_src2();
/*! Bundled license information:

@google-cloud/vertexai/build/src/util/constants.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/util/index.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/functions/util.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/types/errors.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/functions/post_fetch_processing.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/functions/post_request.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/functions/pre_fetch_processing.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/functions/generate_content.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/models/chat_session.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/functions/count_tokens.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/models/generative_models.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/models/index.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/types/common.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/types/content.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/types/tool.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/types/generate_content_response_handler.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/types/index.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/resources/cached_contents.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/resources/shared/api_client.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/resources/index.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/vertex_ai.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google-cloud/vertexai/build/src/index.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *     https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
*/
//# sourceMappingURL=@google-cloud_vertexai.js.map
